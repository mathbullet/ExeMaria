[
  {
    "objectID": "aisuite-tutorial.html",
    "href": "aisuite-tutorial.html",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "",
    "text": "このノートブックでは、LLMとのCUIベースの対話において、LLMプロバイダやモデルの切り替えにかかる労力を最小化するライブラリ、aisuiteについて説明します。"
  },
  {
    "objectID": "aisuite-tutorial.html#背景",
    "href": "aisuite-tutorial.html#背景",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "背景",
    "text": "背景\nHuggingFace TransformersやLangChainといった既存のライブラリを使ってLLMにプロンプトを入力し、出力結果を得ることは可能です。しかし、これらのライブラリは使用するLLMのモデルやプロバイダによってインポートすべきクラスや必要な前後処理が異なる場合があり、これが若干の手間になっています。\n例えばLangChain v.0.3では、LLMのプロバイダごとに異なるパッケージが用意されています。そのため、プロバイダごとにパッケージをインストールし、プロバイダごとに異なるコードでLLMと対話することになります。Anthropic、OpenAIのモデルの出力を比較をしたい、という時は、以下のような手順を踏む必要があります。\npip install \\\n    langchain \\\n    langchain-anthropic \\\n    langchain-openai\n\n# AnthropicのClaude 3 Opusを使用する場合\nfrom langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-3-opus-20240229\")\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n\nはじめまして！私はAnthropic社によって開発されたAI アシスタントのClaudeと申します。人工知能の研究と自然言語処理の技術を用いて、人々のお役に立てるよう頑張っています。どんな話題でもお気軽にお話しいただければと思います。よろしくお願いいたします！\n\n\n\n# OpenAIのGPT-4oを使用する場合\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n\nこんにちは！私はAIアシスタントです。あなたのお手伝いをするためにここにいます。何か質問や相談があれば、お気軽にどうぞ！\n\n\nここでは実行はしませんが、HuggingFaceのモデルを使う場合はさらに差分が大きくなります。\npip install langchain-huggingface\nfrom langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n\nllm = HuggingFaceEndpoint(\n    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n    max_new_tokens=256,\n)\n\nmodel = ChatHuggingFace(llm=llm)\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n毎度使うモデルやプロバイダが変わるたびにコードの書き心地が変わるより、全て統一のインターフェースで使える方がいいよね、というのがaisuiteのモチベーションです。"
  },
  {
    "objectID": "aisuite-tutorial.html#aisuite",
    "href": "aisuite-tutorial.html#aisuite",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "aisuite",
    "text": "aisuite\nそれではaisuiteを触ってみましょう。以下コマンドでインストールします。\npip install 'aisuite[all]'\n先ほどと同じように、複数プロバイダのLLMを使用するとき、プロバイダごとに別途用意する必要があるのは{プロバイダ名}:{モデル名}という形式の文字列のみです。\n\nclaude3opus = \"anthropic:claude-3-opus-20240229\"\ngpt4o = \"openai:gpt-4o\"\n# zephyr = \"huggingface:HuggingFaceH4/zephyr-7b-beta\"\n\nどのプロバイダのどのモデルを使うとしても、モデルからの応答を得る方法は同じです。まずはClientというクラスのインスタンスを作成します。\n\nimport aisuite\n\nclient = aisuite.Client()\n\n併せて、モデルに入力するメッセージも作成しておきます。\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"こんにちは！あなたは誰ですか？\"}\n]\n\nそして、client.chat.completions.createというメソッドによってメッセージの送信を行います。\nClaudeを使う場合は以下のようになります。\n\nresponse = client.chat.completions.create(\n        model=claude3opus,\n        messages=messages\n    )\nprint(response.choices[0].message.content)\n\nこんにちは！私はAnthropic社が開発した人工知能アシスタントです。クロードという名前で、人間とのコミュニケーションを通じて、様々なタスクをサポートすることを目的としています。知識豊富で思慮深く、創造性もあると自負しています。どのようなことでもお気軽にご相談ください。一緒に問題解決に取り組みましょう！\n\n\nGPT-4oを使う場合は以下のようになります。\n\nresponse = client.chat.completions.create(\n        model=gpt4o,\n        messages=messages\n    )\nprint(response.choices[0].message.content)\n\nこんにちは！私はOpenAIが開発したAI言語モデルです。何かご質問やお手伝いできることがあれば教えてください。\n\n\nここで、両者が異なるのはmodelの値のみである点に注目してください。プロバイダやモデルを変えたい場合はここを書き換えるだけでよく、差分が最小化されていることがわかります。\nLLMの性能比較を行う際など、複数のLLMを呼び出して応答を得たい場面で有用ではないかと思います。また、シンプルに綺麗なインターフェースで使いやすいので、さらに機能が追加されて活用できる場面が広がると嬉しいですね。"
  },
  {
    "objectID": "aisuite-tutorial.html#補足",
    "href": "aisuite-tutorial.html#補足",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "補足",
    "text": "補足"
  }
]