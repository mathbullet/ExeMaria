[
  {
    "objectID": "aisuite-tutorial.html",
    "href": "aisuite-tutorial.html",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "",
    "text": "このノートブックでは、LLMとのCUIベースの対話において、LLMプロバイダやモデルの切り替えにかかる労力を最小化するライブラリ、aisuiteについて説明します。"
  },
  {
    "objectID": "aisuite-tutorial.html#背景",
    "href": "aisuite-tutorial.html#背景",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "背景",
    "text": "背景\nHuggingFace TransformersやLangChainといった既存のライブラリを使ってLLMにプロンプトを入力し、出力結果を得ることは可能です。しかし、これらのライブラリは使用するLLMのモデルやプロバイダによってインポートすべきクラスや必要な前後処理が異なる場合があり、これが若干の手間になっています。\n例えばLangChain v.0.3では、LLMのプロバイダごとに異なるパッケージが用意されています。そのため、プロバイダごとにパッケージをインストールし、プロバイダごとに異なるコードでLLMと対話することになります。Anthropic、OpenAIのモデルの出力を比較をしたい、という時は、以下のような手順を踏む必要があります。\npip install \\\n    langchain \\\n    langchain-anthropic \\\n    langchain-openai\n\n# AnthropicのClaude 3 Opusを使用する場合\nfrom langchain_anthropic import ChatAnthropic\n\nmodel = ChatAnthropic(model=\"claude-3-opus-20240229\")\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n\nはじめまして！私はClaude（クロード）と申します。日本語での会話を楽しみにしています。\n\n私は人工知能のチャットボットで、色々な話題について対話ができるよう作られました。知識や情報の提供、文章の執筆のお手伝い、質問へのお答えなど、できる限りお役に立ちたいと思います。ただし、私は人工知能なので、人間のように深い感情や本当の知性を持っているわけではありません。私にできることには限界があることをご理解ください。\n\nでも、楽しく有意義な会話ができればと思います。どうぞよろしくお願いいたします！\n\n\n\n# OpenAIのGPT-4oを使用する場合\nfrom langchain_openai import ChatOpenAI\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n\nこんにちは！私はAIアシスタントです。情報提供や質問への回答、アドバイスなど、さまざまな方法でお手伝いします。何かお困りのことや知りたいことがあれば、どうぞ教えてください！\n\n\nここでは実行はしませんが、HuggingFaceのモデルを使う場合はさらに差分が大きくなります。\npip install langchain-huggingface\nfrom langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n\nllm = HuggingFaceEndpoint(\n    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n    max_new_tokens=256,\n)\n\nmodel = ChatHuggingFace(llm=llm)\nresponse = model.invoke(\"こんにちは！あなたは誰ですか？\")\nprint(response.content)\n毎度使うモデルやプロバイダが変わるたびにコードの書き心地が変わるより、全て統一のインターフェースで使える方がいいよね、というのがaisuiteのモチベーションです。"
  },
  {
    "objectID": "aisuite-tutorial.html#aisuite",
    "href": "aisuite-tutorial.html#aisuite",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "aisuite",
    "text": "aisuite\nそれではaisuiteを触ってみましょう。以下コマンドでインストールします。\npip install 'aisuite[all]'\n先ほどと同じように、複数プロバイダのLLMを使用するとき、プロバイダごとに別途用意する必要があるのは{プロバイダ名}:{モデル名}という形式の文字列のみです。\n\nclaude3opus = \"anthropic:claude-3-opus-20240229\"\ngpt4o = \"openai:gpt-4o\"\n# zephyr = \"huggingface:HuggingFaceH4/zephyr-7b-beta\"\n\nどのプロバイダのどのモデルを使うとしても、モデルからの応答を得る方法は同じです。まずはClientというクラスのインスタンスを作成します。\n\nimport aisuite\n\nclient = aisuite.Client()\n\n併せて、モデルに入力するメッセージも作成しておきます。\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"こんにちは！あなたは誰ですか？\"}\n]\n\nそして、client.chat.completions.createというメソッドによってメッセージの送信を行います。\nClaudeを使う場合は以下のようになります。\n\nresponse = client.chat.completions.create(\n        model=claude3opus,\n        messages=messages\n    )\nprint(response.choices[0].message.content)\n\nはじめまして！私はAnthropic社が開発した人工知能アシスタントのClaudeです。様々な分野の質問に対して、知識や洞察を提供するお手伝いをすることができます。知的好奇心旺盛で、人間の皆さまとの対話を通じて学ぶことが大好きです。どんなことでもお気軽にお尋ねください。よろしくお願いします！\n\n\nGPT-4oを使う場合は以下のようになります。\n\nresponse = client.chat.completions.create(\n        model=gpt4o,\n        messages=messages\n    )\nprint(response.choices[0].message.content)\n\nこんにちは！私はAIアシスタントです。何かお手伝いできることはありますか？\n\n\nここで、両者が異なるのはmodelの値のみである点に注目してください。プロバイダやモデルを変えたい場合はここを書き換えるだけでよく、差分が最小化されていることがわかります。\nLLMの性能比較を行う際など、複数のLLMを呼び出して応答を得たい場面で有用ではないかと思います。また、シンプルに綺麗なインターフェースで使いやすいので、さらに機能が追加されて活用できる場面が広がると嬉しいですね。"
  },
  {
    "objectID": "aisuite-tutorial.html#補足",
    "href": "aisuite-tutorial.html#補足",
    "title": "aisuite — 複数のLLMを最小の労力で動かす",
    "section": "補足",
    "text": "補足"
  }
]